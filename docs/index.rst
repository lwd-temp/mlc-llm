ğŸ‘‹ Welcome to MLC LLM
===================================

`Discord <https://discord.gg/9Xpy2HGBuD>`_ | `Demo <https://mlc.ai/mlc-llm>`_ | `GitHub <https://github.com/mlc-ai/mlc-llm>`_

ğŸš§ This document is currently undergoing heavy construction.

Machine Learning Compilation for LLM (MLC LLM) is a universal deployment solution that enables LLMs to run efficiently on consumer devices, leveraging native hardware acceleration like GPUs.

.. table:: MLC LLM: A universal deployment solution for large language models
   :widths: 200, 250, 250, 250, 250
   :align: center

   +-------------------+-------------------+-------------------+-------------------+---------------------+
   |                   |  AMD GPU          | NVIDIA GPU        | Apple M1/M2 GPU   | Intel GPU           |
   +===================+===================+===================+===================+=====================+
   |   Linux / Win     | âœ… Vulkan, ROCm   | âœ… Vulkan, CUDA   | âŒ                | âœ… Vulkan           |
   +-------------------+-------------------+-------------------+-------------------+---------------------+
   |   macOS           | âœ… Metal          | âŒ                | âœ… Metal          | âœ… Metal            |
   +-------------------+-------------------+-------------------+-------------------+---------------------+
   |   Web Browser     | âœ… WebGPU         | âœ… WebGPU         | âœ… WebGPU         | âœ… WebGPU           |
   +-------------------+-------------------+-------------------+-------------------+---------------------+
   |   iOS / iPadOS    | âœ… Metal on Apple M1/M2 GPU                                                     |
   +-------------------+-------------------+-------------------+-------------------+---------------------+
   |   Android         | âœ… OpenCL, Vulkan on Snapdragon, Mali GPU                                       |
   +-------------------+-------------------+-------------------+-------------------+---------------------+


Project Structure
-----------------

The project comprises three independent modules: model definition, model compilation, and runtimes.

.. image:: _static/img/project-structure.svg
   :width: 600
   :align: center
   :alt: Project Structure

.. â€ââ‚âƒâ„â…â†â‡âˆâ‰
.. âŠâ‹âŒâââââ‘â’â“

**â€ Model definition in Python.** MLC offers a variety of pre-defined architectures, such as Llama (e.g., Vicuna, OpenLlama, Llama, Wizard), GPT-NeoX (e.g., RedPajama, Dolly), RNNs (e.g., RWKV), and GPT-J (e.g., MOSS). Model developers could solely define the model in pure Python, without having to touch code generation and runtime.

**â Model compilation in Python.** TVM Unity compiler are configured in pure python, and the compiled artifact can be exported as shared or static libraries. Performance experts can concentrate on compiler optimization to enhance the speed of LLMs on specific devices of interest.

**â‚ Platform-native runtimes.** MLCChat are provided as lightweight runtimes tailored for each platform, including **C++** for command line, **Javascript** for web, **Swift** for iOS, and **Java** for Android. App developers only need to familiarize themselves with the platform-naive runtimes to integrate MLC-compiled LLM into their applications.

Docs by Usecases
----------------

**TODO** Verticals

.. tabs ::

   .. tab :: â‚ Run Compiled Models

      MLCChat is a lightweight runtime designed to demonstrate how to integrate MLC-compiled LLMs:

      - ğŸš§ CLI
      - ğŸš§ WebLLM
      - ğŸš§ iOS
      - ğŸš§ Android

      Moreover, to incorporate MLC-compiled models without using MLCChat:

      - ğŸš§ Use MLC-compiled models in a C++ project
      - ğŸš§ Use MLC-compiled models in a Javascript project
      - ğŸš§ Use MLC-compiled models in an iOS project
      - ğŸš§ Use MLC-compiled models in an Android project

      **Note.** TVM Unity compiler is not a dependency to running any MLC-compiled model.

   .. tab :: â Compile Models

      TVM Unity is required to compile models. :ref:`Installation Guidelines <tvm-unity-install-prebuilt-package>`.

      - ğŸš§ MLC LLM Build walkthrough
      - ğŸš§ Compilation artifact specification
      - ğŸš§ Configure hardware targets
      - ğŸš§ Configure quantization formats

   .. tab :: â€ Define Model Architectures

      TVM Unity is required to define models. :ref:`Installation Guidelines <tvm-unity-install-prebuilt-package>`.

      - ğŸš§ Define new model architectures: :doc:`tutorials/bring-your-own-models`.
      .. - ğŸš§ Contribute new models: :ref:`contribute-new-models`.

   .. tab :: MLC-Prebuilt LLMs

      - ğŸš§ Off-the-shelf prebuilt models: :ref:`off-the-shelf-models`

.. - Machine Learning Compilation Basics: `Machine Learning Compilation <https://mlc.ai/>`__


.. toctree::
   :maxdepth: 1
   :caption: All tutorials

   install/index.rst
   install/software-dependencies.rst
   tutorials/deploy-models.rst
   tutorials/compile-models.rst
   tutorials/bring-your-own-models.rst
   tutorials/customize.rst

.. toctree::
   :maxdepth: 1
   :caption: Contribute to MLC-LLM

   contribute/community.rst

.. toctree::
   :maxdepth: 1
   :caption: Model Prebuilts

   model-prebuilts.rst

.. toctree::
   :maxdepth: 1
   :caption: Misc

   misc/faq.rst
